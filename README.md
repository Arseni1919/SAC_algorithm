# My SAC implementation

## The Algorithm

### Pseudocode


![pseudocode](static/pseudocode.png)


## `LunarLanderContinuous-v2` parameters:
```

```

Algorithm's net:
```

```

## `BipedalWalker-v3` parameters:
```

```

Algorithm's net:
```

```

## Credits:

- [SAC | OpenAI](https://spinningup.openai.com/en/latest/algorithms/sac.html#pseudocode)
- [Environments in OpenAI](https://gym.openai.com/envs/#box2d)
- [Deep-Reinforcement-Learning-Hands-On-Second-Edition](https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On-Second-Edition/tree/master/Chapter17)
- [Policy Gradient Algorithms | Lilian Weng's Blog](https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html)
- [DATASETS & DATALOADERS | PyTorch](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)
- [SAVING AND LOADING MODELS | PyTorch](https://pytorch.org/tutorials/beginner/saving_loading_models.html)
- [PROBABILITY DISTRIBUTIONS - TORCH.DISTRIBUTIONS | PyTorch](https://pytorch.org/docs/stable/distributions.html)
- [Reparameterization Trick](https://stats.stackexchange.com/a/226136)
- [SAC implementation | TDS](https://towardsdatascience.com/soft-actor-critic-demystified-b8427df61665), [(code)](https://github.com/vaishak2future/sac/blob/master/sac.ipynb)











